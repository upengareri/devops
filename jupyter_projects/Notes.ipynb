{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker\n",
    "\n",
    "### Purging all dangling images, container, volumes and networks\n",
    "\n",
    "`docker system prune` _Prune means to remove unwanted stuff_\n",
    "\n",
    "`docker system prune -a` _To remove all_\n",
    "\n",
    "## ----------------------------------- CONTAINERS -----------------------------------\n",
    "\n",
    "### List all containers\n",
    "`docker ps -a`\n",
    "\n",
    "`docker ps -aq` [q: only ids]\n",
    "\n",
    "### Stop all running containers\n",
    "`docker stop $(docker ps -aq)`\n",
    "\n",
    "### Remove all containers\n",
    "`docker rm $(docker ps -aq)`\n",
    "\n",
    "### Run and remove\n",
    "`docker run -rm image_name`\n",
    "\n",
    "### Remove only exited containers\n",
    "`docker rm $(docker ps -aq -f status=exited)`\n",
    "\n",
    "### Remove containers according to pattern\n",
    "`docker ps -a | grep \"pattern\" | awk '{print $1}' | xargs docker rm`\n",
    "> awk and xargs to supply the ID to docker rm\n",
    "\n",
    "## ----------------------------------- IMAGES -----------------------------------\n",
    "\n",
    "### List images\n",
    "`docker images`\n",
    "\n",
    "### Remove all images\n",
    "`docker rmi $(docker images -aq)` _q: for id_\n",
    "\n",
    "### List dangling images\n",
    "`docker images -f dangling=true`\n",
    "\n",
    "### Remove dangline images\n",
    "`docker image prune`\n",
    "\n",
    "### Remove images according to pattern\n",
    "`docker images -a | grep \"pattern\" | awk '{print $3}' | xargs docker rmi`\n",
    "\n",
    "\n",
    "## ----------------------------------- VOLUMES -----------------------------------\n",
    "\n",
    "### List volumes\n",
    "`docker volume ls`\n",
    "\n",
    "### Remove volume\n",
    "`docker volume rm vol_name`\n",
    "\n",
    "### List dangling volumes\n",
    "`docker volume ls -f dangling=true`\n",
    "\n",
    "### Remove dangling volumes\n",
    "`docker volume prune`\n",
    "\n",
    "## Remove container and its volume\n",
    "`docker rm -v container_name`\n",
    "\n",
    "__SUMMARY__\n",
    "> docker system prune\n",
    "\n",
    "> docker rmi\n",
    "\n",
    "> docker rm\n",
    "\n",
    "> docker volume rm\n",
    "\n",
    "-----------\n",
    "\n",
    "\n",
    "### To run bash on docker image\n",
    "```bash\n",
    "# Assuming an Ubuntu Docker image\n",
    "$ docker run -it --name <container_name> <image> /bin/bash\n",
    "```\n",
    "\n",
    "> This won't work if your image has a defined ENTRYPOINT. For these cases use: `docker run -it --entrypoint /bin/bash <image>`\n",
    "\n",
    "### To go inside container running in detached state\n",
    "`docker exec -it cc73eb6d6f75 bash`\n",
    "\n",
    "------------\n",
    "\n",
    "## Theory on Docker and Docker Layer Caching\n",
    "\n",
    "This is where the paradigm shift comes into place: software is no longer packaged as a platform-specific binary artifact (jar, dll, tgz) but as a fully fledged virtual environment in the form of Docker images. This means that developers can run the code locally exactly as it is run on dev, test or prod environments. The operations teams have only Docker images to deal with, with much less need to understand the inner workings of the specific platform they are deploying.\n",
    "\n",
    "Every time you change or update the application code, you need to build a new version of the image that can be used for deployment. Even though you’d typically only change the application code, the entire image needs to be built from scratch — including all dependencies. To help with the efficiency of the typical development process and shorten the feedback loop cycle, Docker has introduced the concept of layer caching.\n",
    "\n",
    "## Theory on Docker Compose and Buildkit\n",
    "\n",
    "We can use `docker build` and `docker run` to build and test/run our applications. But if we have multiple docker files for e.g for client app and one for server then to switch back and forth and build and run these can be cumbersome. To solve this, we have `docker-compose` that can build and run with just one command.\n",
    "\n",
    "With the help of Buildkit (still experimental) we can use caching layer service of docker build into docker-compose. When we use docker build and then docker compose the docker compose builds the dockerfile from scratch and doesn't use the cache of docker build that we ran first time. With the help of buildkit command docker-compose will re-use the cache layer.\n",
    "\n",
    "Note: when we use builtkit for the first time, it'll create it's own layer storage strategy. This means it'll build the docker image from scratch but then after that when we use docker-compose, it will use the buildkit cache storage and would not build from scratch.\n",
    "\n",
    "Brief introduction [5mins read]: https://medium.com/better-programming/sharing-cached-layer-between-docker-and-docker-compose-builds-c2e5f751cee4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker Contd.\n",
    "\n",
    "## Share data between docker container and host\n",
    "\n",
    "## Bind mount volumes\n",
    "\n",
    "Docker containers are emphemeral meaning any data created inside the container is only available in that container and only while the container is running.\n",
    "\n",
    "__Scenario__:\n",
    "\n",
    "Let's say we want to run nginx container and keep the permanent copy of log files generated during it's run for later analysis. Nginx log files are generated at /var/log/nginx by default and it is not accessible from host system.\n",
    "\n",
    "__Step 1: Bindmount Volume__:\n",
    "\n",
    "`docker run --name=nginx -d -v ~/nginx_logs:/var/logs/nginx -p 5000:80 nginx`\n",
    "\n",
    "* `--name=nginx` names the container so that we can refer it easily\n",
    "* `-d` run the container in detached state i.e in background so that we can have access to the terminal from where we are running the docker run command\n",
    "* `-v ~/nginx_logs:/var/logs/nginx` bindmounts volume that links `/var/logs/nginx` directory from inside the container to `~/nginx_logs` directory of the host. Docker uses __`:`__ to split host path with container path and __host path always comes first__. \n",
    "* `-p 5000:80` __port forwarding__. This flag maps container's port 80 to port 5000 of the host machine.\n",
    "* `nginx` name of the image\n",
    "\n",
    "> The -v flag is very flexible. It can bindmount or name a volume with just a slight adjustment in syntax. If the first argument begins with a / or ~/, you’re creating a bindmount. Remove that, and you’re naming the volume.\n",
    "For more details: https://www.digitalocean.com/community/tutorials/how-to-share-data-between-docker-containers\n",
    "\n",
    "__Step 2: Access Data on Host__:\n",
    "Just go to the directory `~/nginx_logs` and see the log file.\n",
    "> If you make any changes to the `~/nginx_logs` folder, you’ll be able to see them from inside the Docker container in real time as well.\n",
    "\n",
    "> Multiple containers can share the same bind mount.\n",
    "\n",
    "## Named Volumes\n",
    "\n",
    "- They are more recent ways of creating volumes and they exist outside the container lifecycle.\n",
    "- Named volumes support more feature thatn bindmount such as remote cloud storage\n",
    "\n",
    "```docker\n",
    "docker create volume my_volume\n",
    "docker run -v my_volume:/directory/in/container ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker Syntax\n",
    "\n",
    "EXAMPLE 1:\n",
    "```python\n",
    "FROM node:10.9.0\n",
    "\n",
    "COPY . .\n",
    "\n",
    "RUN npm install\n",
    "\n",
    "EXPOSE 8080\n",
    "\n",
    "CMD npm start\n",
    "\n",
    "# EXPLANATION:\n",
    "\n",
    "# FROM it's better to use version rather than latest as the latest will override the current working docker image and if the latest image has problem then it's tricky to roll back. Versioning gives more control\n",
    "\n",
    "# COPY current directory to working directory in container. Here the working dir of container will inherit from node image.\n",
    "# ADD is more advanced/powerful than COPY. For e.g it automatically extracts the archive and it has support for URLs. Use COPY by default to avoid any surprises unless you specifically need it.\n",
    "\n",
    "# RUN will run the shell command in the current workind directory\n",
    "\n",
    "# EXPOSE tell what port the container should be listening on. It's merely for documentation as it does not actually publish the port number on the host machine. To publish the ports and enable the client to connect to them, we need to use `-p` flag from the command line \n",
    "\n",
    "# CMD tells what command to run when someone starts the container. The above cmd tells docker to run node server for our application on start.\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bash\n",
    "\n",
    "1. find [where_to_find] -name [what_to_find]\n",
    "\n",
    "e.g `find / -name *.whl`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GetIntoDevOps Notes\n",
    "\n",
    "### CI\n",
    "\n",
    "- Emphasises automated testing to ensure the new code changes work as intended and does not break anything (fast feedback)\n",
    "- Pipeline automation servers (like Jenkins) are used to implement automatic testing\n",
    "\n",
    "### CD (Continuous Delivery)\n",
    "\n",
    "- While CI is the act of merging code as fast as possible, CD is the act of shipping changes to production frequently, in small increments\n",
    "- In practice, the code in main branch should be deployable to production at all times\n",
    "\n",
    "### CD (Continuous Deployment)\n",
    "\n",
    "- While Delivery makes sure everything in the main branch should be in deployable state, the actual automation of deployment without human intervention is part of this stage.\n",
    "\n",
    "### A/B Testing\n",
    "\n",
    "- Introducing two changes in the application and measuring which variant works better\n",
    "\n",
    "### \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Journey Questions\n",
    "\n",
    "1. Basic pipeline running for various repos\n",
    "2. Use docker\n",
    "3. Implement bazel caching\n",
    "4. Implement docker caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
