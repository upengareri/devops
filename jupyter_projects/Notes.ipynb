{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker\n",
    "\n",
    "### Purging all dangling images, container, volumes and networks\n",
    "\n",
    "`docker system prune` _Prune means to remove unwanted stuff_\n",
    "\n",
    "`docker system prune -a` _To remove all_\n",
    "\n",
    "## ----------------------------------- CONTAINERS -----------------------------------\n",
    "\n",
    "### List all containers\n",
    "`docker ps -a`\n",
    "\n",
    "`docker ps -aq` [q: only ids]\n",
    "\n",
    "### Stop all running containers\n",
    "`docker stop $(docker ps -aq)`\n",
    "\n",
    "### Remove all containers\n",
    "`docker rm $(docker ps -aq)`\n",
    "\n",
    "### Run and remove\n",
    "`docker run -rm image_name`\n",
    "\n",
    "### Remove only exited containers\n",
    "`docker rm $(docker ps -aq -f status=exited)` _-f means filter_\n",
    "\n",
    "### Remove containers according to pattern\n",
    "`docker ps -a | grep \"pattern\" | awk '{print $1}' | xargs docker rm`\n",
    "> awk and xargs to supply the ID to docker rm\n",
    "\n",
    "## ----------------------------------- IMAGES -----------------------------------\n",
    "\n",
    "### List images\n",
    "`docker images`\n",
    "\n",
    "### Remove all images\n",
    "`docker rmi $(docker images -aq)` _q: for id_\n",
    "\n",
    "### List dangling images\n",
    "`docker images -f dangling=true`\n",
    "\n",
    "### Remove dangline images\n",
    "`docker image prune`\n",
    "\n",
    "### Remove images according to pattern\n",
    "`docker images -a | grep \"pattern\" | awk '{print $3}' | xargs docker rmi`\n",
    "\n",
    "\n",
    "## ----------------------------------- VOLUMES -----------------------------------\n",
    "\n",
    "### List volumes\n",
    "`docker volume ls`\n",
    "\n",
    "### Remove volume\n",
    "`docker volume rm vol_name`\n",
    "\n",
    "### List dangling volumes\n",
    "`docker volume ls -f dangling=true`\n",
    "\n",
    "### Remove dangliing volumes\n",
    "`docker volume prune`\n",
    "\n",
    "## Remove container and its volume\n",
    "`docker rm -v container_name`\n",
    "\n",
    "__SUMMARY__\n",
    "> docker system prune\n",
    "\n",
    "> docker rmi\n",
    "\n",
    "> docker rm\n",
    "\n",
    "> docker volume rm\n",
    "\n",
    "-----------\n",
    "\n",
    "\n",
    "### To run bash on docker image\n",
    "```bash\n",
    "# Assuming an Ubuntu Docker image\n",
    "$ docker run -it --name <container_name> <image> /bin/bash\n",
    "```\n",
    "\n",
    "> This won't work if your image has a defined ENTRYPOINT. For these cases use: `docker run -it --entrypoint /bin/bash <image>`\n",
    "\n",
    "### To go inside container running in detached state\n",
    "`docker exec -it cc73eb6d6f75 bash`\n",
    "\n",
    "------------\n",
    "\n",
    "## Theory on Docker and Docker Layer Caching\n",
    "\n",
    "This is where the paradigm shift comes into place: software is no longer packaged as a platform-specific binary artifact (jar, dll, tgz) but as a fully fledged virtual environment in the form of Docker images. This means that developers can run the code locally exactly as it is run on dev, test or prod environments. The operations teams have only Docker images to deal with, with much less need to understand the inner workings of the specific platform they are deploying.\n",
    "\n",
    "Every time you change or update the application code, you need to build a new version of the image that can be used for deployment. Even though you’d typically only change the application code, the entire image needs to be built from scratch — including all dependencies. To help with the efficiency of the typical development process and shorten the feedback loop cycle, Docker has introduced the concept of layer caching.\n",
    "\n",
    "## Theory on Docker Compose and Buildkit\n",
    "\n",
    "We can use `docker build` and `docker run` to build and test/run our applications. But if we have multiple docker files for e.g for client app and one for server then to switch back and forth and build and run these can be cumbersome. To solve this, we have `docker-compose` that can build and run with just one command.\n",
    "\n",
    "With the help of Buildkit (still experimental) we can use caching layer service of docker build into docker-compose. When we use docker build and then docker compose the docker compose builds the dockerfile from scratch and doesn't use the cache of docker build that we ran first time. With the help of buildkit command docker-compose will re-use the cache layer.\n",
    "\n",
    "Note: when we use builtkit for the first time, it'll create it's own layer storage strategy. This means it'll build the docker image from scratch but then after that when we use docker-compose, it will use the buildkit cache storage and would not build from scratch.\n",
    "\n",
    "Brief introduction [5mins read]: https://medium.com/better-programming/sharing-cached-layer-between-docker-and-docker-compose-builds-c2e5f751cee4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bash\n",
    "\n",
    "1. find [where_to_find] -name [what_to_find]\n",
    "\n",
    "e.g `find / -name *.whl`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Journey Questions\n",
    "\n",
    "1. Basic pipeline running for various repos\n",
    "2. Use docker\n",
    "3. Implement bazel caching\n",
    "4. Implement docker caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
