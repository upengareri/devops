{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker\n",
    "\n",
    "### List all containers\n",
    "`docker ps -a`\n",
    "`docker ps -aq` [Only ids]\n",
    "\n",
    "### Stop all running containers\n",
    "`docker stop $(docker ps -aq)`\n",
    "\n",
    "### Remove all containers\n",
    "`docker rm $(docker ps -aq)`\n",
    "\n",
    "### Remove all images\n",
    "`docker rm $(docker images)`\n",
    "\n",
    "### To run bash on docker image\n",
    "```bash\n",
    "# Assuming an Ubuntu Docker image\n",
    "$ docker run -it --name <container_name> <image> /bin/bash\n",
    "```\n",
    "\n",
    "> This won't work if your image has a defined ENTRYPOINT. For these cases use: `docker run -it --entrypoint /bin/bash <image>`\n",
    "\n",
    "\n",
    "## Theory on Docker and Docker Layer Caching\n",
    "\n",
    "This is where the paradigm shift comes into place: software is no longer packaged as a platform-specific binary artifact (jar, dll, tgz) but as a fully fledged virtual environment in the form of Docker images. This means that developers can run the code locally exactly as it is run on dev, test or prod environments. The operations teams have only Docker images to deal with, with much less need to understand the inner workings of the specific platform they are deploying.\n",
    "\n",
    "Every time you change or update the application code, you need to build a new version of the image that can be used for deployment. Even though you’d typically only change the application code, the entire image needs to be built from scratch — including all dependencies. To help with the efficiency of the typical development process and shorten the feedback loop cycle, Docker has introduced the concept of layer caching.\n",
    "\n",
    "## Theory on Docker Compose and Buildkit\n",
    "\n",
    "We can use `docker build` and `docker run` to build and test/run our applications. But if we have multiple docker files for e.g for client app and one for server then to switch back and forth and build and run these can be cumbersome. To solve this, we have `docker-compose` that can build and run with just one command.\n",
    "\n",
    "With the help of Buildkit (still experimental) we can use caching layer service of docker build into docker-compose. When we use docker build and then docker compose the docker compose builds the dockerfile from scratch and doesn't use the cache of docker build that we ran first time. With the help of buildkit command docker-compose will re-use the cache layer.\n",
    "\n",
    "Note: when we use builtkit for the first time, it'll create it's own layer storage strategy. This means it'll build the docker image from scratch but then after that when we use docker-compose, it will use the buildkit cache storage and would not build from scratch.\n",
    "\n",
    "Brief introduction [5mins read]: https://medium.com/better-programming/sharing-cached-layer-between-docker-and-docker-compose-builds-c2e5f751cee4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bash\n",
    "\n",
    "1. find [where_to_find] -name [what_to_find]\n",
    "\n",
    "e.g `find / -name *.whl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
